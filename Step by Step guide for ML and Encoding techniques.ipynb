{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7271f6fa-ca12-4f45-8e90-433c37feaefc",
   "metadata": {},
   "source": [
    "# Don't Run the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea0021-adaf-49cc-bfd0-56eb8512e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859bd0c-9b20-4331-9a2a-e9c1d6c79538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Read the Dataset\n",
    "\n",
    "# Assuming the dataset is stored in a CSV file named 'dataset.csv'\n",
    "data = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ff40e-84ab-4194-aba1-c471d0e829f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Feature Engineering (if needed)\n",
    "#If you need to perform any feature engineering tasks like handling missing values, encoding categorical variables, or creating new features, you can do so at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987dfc42-2d25-451d-a332-714b87509251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split Data into Features (X) and Target Variable (y)\n",
    "\n",
    "X = data.drop(columns=['target_column'])  # Drop the target variable column\n",
    "y = data['target_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daa141-6966-4aa0-a563-78ec14737263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdca6a-7ada-42f7-acc7-8f8cf5b867ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature Scaling (if needed)\n",
    "\n",
    "# If your models require feature scaling (e.g., logistic regression), you can scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca73a05-f13c-4a11-bd4f-600dfb48bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Feature Selection\n",
    "\n",
    "# Select the top k features using ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5fddf-2479-4d4a-89de-6cc562e05d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Define and Train Models\n",
    "\n",
    "# Define classifiers\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier()\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182dc2b2-39d9-40d9-806a-1fa31b6f644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate Models\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f'{name}: Accuracy = {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c71148-adb5-4f6f-a596-2004262ad365",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb407b73-1971-4e33-bcde-a7a5aba7c5c3",
   "metadata": {},
   "source": [
    "#### Let's say we have IF - Height(cm), Weight(kg) and DF - BMI\n",
    "#### Magnitude is value (height example - 183) and Unit is cm\n",
    "\n",
    "##### 1. If we directly apply ML algorith (let's say KNN (it works on Eucledian Distance)) and if we take the same magnitude and plot this in a 2D graph then points will be having varying distance or the distances will be huge.\n",
    "##### 2. Scaling also happens with respect to that feature \n",
    "##### 3. Algorithms in which Scaling is compulsory :-\n",
    "* Linear Regression (After scaling the random coefficient (starting point on global minima) will get close to global minima in the beginning as well), our convergence will happen quickly\n",
    "* Algorithms in which Eucledian distance is used (K means clustering, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331fe0f-571b-482b-8e21-0c3756ec9955",
   "metadata": {},
   "source": [
    "# When should we not apply Feature Scaling\n",
    "\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354de0a-c610-4477-ae5a-483ff3de33dc",
   "metadata": {},
   "source": [
    "# Standardization and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f98c98-1365-46c0-8e03-9c08661f2693",
   "metadata": {},
   "source": [
    "1. Normalization helps us to scale down our features between 0 to 1\n",
    "2. Standadization helps us to scale down our features based on Standard Normal Distribution (mean-0, std deviation-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98597f19-fe81-41e4-9aef-14170aa146df",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "1. Whenever we talk about Encoding Techniques, it means we are talking about categorical variables\n",
    "2. For ex we have gender feature (male,female). If we directly provide these values to ML algorith then it will not be able to understand because ML algorithms involves a lot of mathematical calculations\n",
    "\n",
    "## Types of Encoding\n",
    "1. Nominal Encoding\n",
    "   * One Hot Encoding\n",
    "   * One Hot Encoding with many Categorical Variables\n",
    "   * Mean Encoding\n",
    "---------------------------------\n",
    "---------------------------------\n",
    "2. Ordinal Encoding\n",
    "   * Label Encoding\n",
    "   * Target Guided Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03490a4b-bf46-4038-9993-cd5c795674f1",
   "metadata": {},
   "source": [
    "## Nominal Data\n",
    "1. These categories have no intrinsic order or ranking.\n",
    "2. Examples of nominal categories include gender (male, female), marital status (single, married, divorced), and types of fruits (apple, banana, orange).\n",
    "3. Nominal data can be represented by numbers, but the numbers do not have any mathematical meaning. For example, assigning \"1\" to male and \"2\" to female does not imply any mathematical operation between male and female.\n",
    "4. Statistical measures such as mode (most frequent value) and frequency distributions are commonly used to describe nominal data.\n",
    "\n",
    "## Ordinal Data\n",
    "1. Ordinal categories, unlike nominal, have a natural order or ranking between the categories.\n",
    "2. The differences between categories are not necessarily uniform, but there's a clear hierarchy or sequence.\n",
    "3. Examples of ordinal categories include ratings (poor, fair, good, excellent), educational levels (high school, bachelor's, master's, PhD), and socio-economic status (low, middle, high).\n",
    "4. In ordinal data, the order matters, but the differences between the categories may not be equal.\n",
    "5. Statistical measures such as median and percentile can be used with ordinal data, but arithmetic operations like addition and subtraction are not meaningful because the intervals between categories may not be consistent.\n",
    "  \n",
    "#### In summary, nominal categories are used for labeling and categorizing data without any inherent order, while ordinal categories have a natural order or hierarchy between the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713da5f7-f936-4381-b2bb-9f836178b3a6",
   "metadata": {},
   "source": [
    "## 1. One Hot Encoding\n",
    "\n",
    "Let's say we have country feature in which we have \"Germany\", \"France\", \"Spain\". Now 3 separate features will be created named as Germany, France, Spain and values will be provided as (if germany is present in the original feature then 1 will be given to Germany and 0,0 will be given to the remaining features). We Germany is 0 and France is also 0 then it means Spain is 1, with the help of this idea we can delete the Spain column.\n",
    "This is called as Dummy variable trap.\n",
    "We can do this with the help of pandas (pd.get_dummies) and sklearn as well.\n",
    "\n",
    "#### Disadvantage\n",
    "Let's say we have 100 unique categories so it means 99 columns will get created that means we are increasing the number of dimensions and that leads to CURSE OF DIMENSIONALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b57dfa-cfe0-4c30-8597-d2525d55f4a3",
   "metadata": {},
   "source": [
    "## 2. One Hot Encoding with Multiple Categories\n",
    "\n",
    "Let's say we have 50 different categories in a feature. We will see top 10 categories that are getting repeated more than the others and will apply one hot encoding to these categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d8e9b-0417-491d-a1b0-fddcbf8212ff",
   "metadata": {},
   "source": [
    "## 3. Mean Encoding\n",
    "\n",
    "##### ----Learn Target Encoding first then read this----\n",
    "\n",
    "In this we also take the output feature. Let's say featuer f1 is having (A,B,C,D,A,B...) and output is (1,1,0,0,0,1...) respectively (classification problem). Now we will calculate the mean of \"A\" using the value of output wrt \"A\" and similarly for B,C,D. Now the original values will directly be replaced by the mean values of the respective category. For example - A category is have mean of 0.73 now we will directly replace A with 0.73\n",
    "\n",
    "##### When to use?\n",
    "* When we have pincodes like feature in which we have 1000 records and we don't need to care about the ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967ca0c-78ad-4f37-aa6f-031ceba936b4",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0aa34-953c-4ad3-bd57-f9e9d210f5f6",
   "metadata": {},
   "source": [
    "## 1. Label Encoding\n",
    "\n",
    "Let's say we have Education feature in which we have BE, Master's, PHD, Diploma, now we will give the ranking and in this we are giving rank 4 to PHD (considering the Rank 1 is lowest and Rank 4 is highest).\n",
    "We have Label Encoder library in Sklearn to do this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa4cbf-1eed-457a-9a55-0dec564e964b",
   "metadata": {},
   "source": [
    "## 2. Target Guided Ordinal Encoding\n",
    "\n",
    "In this we also take the output feature. Let's say featuer f1 is having (A,B,C,D,A,B...) and output is (1,1,0,0,0,1...) respectively (classification problem). Now we will calculate the mean of \"A\" using the value of output wrt \"A\" and similarly for B,C,D. Now based on this mean values we are going to assign the Ranks. Higher the value of mean, higher will be the Rank (1 is lowest, 4 is highest)\n",
    "\n",
    "##### When to use?\n",
    "* When we have ordinal variables and along with many categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd635f-4ae6-4a71-93e2-523277e5c8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
